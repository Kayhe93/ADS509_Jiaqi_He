{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "fyO2Mnc8JfqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oPVviB87kVXB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "# for the lyrics scrape section\n",
        "import requests\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict, Counter\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Lyrics Scrape"
      ],
      "metadata": {
        "id": "gBYrYOUOJhPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artists = {'taylor':\"https://www.azlyrics.com/t/taylorswift.html\",\n",
        "           'ed':\"https://www.azlyrics.com/e/edsheeran.html\"}\n",
        "# we'll use this dictionary to hold both the artist name and the link on AZlyrics"
      ],
      "metadata": {
        "id": "FLQ40jhiJgws"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Note on Rate Limiting"
      ],
      "metadata": {
        "id": "OBUYU43dJ2pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Finding Links to Songs Lyrics\n",
        "\n",
        "Q: Take a look at the robots.txt page on www.azlyrics.com. (You can read more about these pages here.) Is the scraping we are about to do allowed or disallowed by this page? How do you know?\n",
        "\n",
        "A: It's disallowed by this page. Search https://www.azlyrics.com/robots.txt, we can get the info as below:\n",
        "\n",
        "User-agent: *\n",
        "\n",
        "Disallow: /lyricsdb/\n",
        "\n",
        "Disallow: /song/\n",
        "\n",
        "Allow: /\n",
        "\n",
        "User-agent: 008\n",
        "\n",
        "Disallow: /"
      ],
      "metadata": {
        "id": "nS2xxzNJKAxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's set up a dictionary of lists to hold our link\n",
        "\n",
        "lyrics_pages = defaultdict(list)\n",
        "\n",
        "for artist, artist_page in artists.items():\n",
        "    # request the page and sleep\n",
        "    r = requests.get(artist_page)\n",
        "    time.sleep(5 + 10 * random.random())\n",
        "\n",
        "    # now extract the links to lyrics pages from this page\n",
        "    # store the links `lyrics_pages` where the key is the artist and the\n",
        "    # value is a list of links.\n",
        "    if r.status_code == 200:\n",
        "        soup = BeautifulSoup(r.text, 'html.parser')\n",
        "        links =soup.find_all(\"a\", href=True)\n",
        "\n",
        "        if links:\n",
        "            # Extract the href attribute from each link and store in lyrics_pages\n",
        "            lyrics_pages[artist] = [link['href'] for link in links]\n",
        "            print(f\"Found {len(lyrics_pages[artist])} lyrics pages for {artist}\")\n",
        "        else:\n",
        "            print(f\"No lyrics links found for {artist}\")\n",
        "\n",
        "    # now extract the links to lyrics pages from this page\n",
        "    # store the links `lyrics_pages` where the key is the artist and the\n",
        "    # value is a list of links.\n",
        "    # Check if the request was successful (status code 200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNTemlMkJ5dj",
        "outputId": "90d25f95-d4a6-4de5-85db-ab4f21ae7885"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 lyrics pages for taylor\n",
            "Found 1 lyrics pages for ed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for artist, lp in lyrics_pages.items() :\n",
        "    assert(len(set(lp)) > 20)"
      ],
      "metadata": {
        "id": "XErXX4I9KNMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a82120d6-772f-4cba-8383-d2088081f2ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-465612e6a19f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlyrics_pages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how long it's going to take to pull these lyrics\n",
        "# if we're waiting `5 + 10*random.random()` seconds\n",
        "for artist, links in lyrics_pages.items() :\n",
        "    print(f\"For {artist} we have {len(links)}.\")\n",
        "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
      ],
      "metadata": {
        "id": "8-Ic2Cz1KPO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63077eae-8a01-41d3-c2de-ae5ad59eeb49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For taylor we have 1.\n",
            "The full pull will take for this artist will take 0.0 hours.\n",
            "For ed we have 1.\n",
            "The full pull will take for this artist will take 0.0 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Pulling Lyrics"
      ],
      "metadata": {
        "id": "hn26XmqdJyxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_filename_from_link(link) :\n",
        "\n",
        "    if not link :\n",
        "        return None\n",
        "\n",
        "    # drop the http or https and the html\n",
        "    name = link.replace(\"https\",\"\").replace(\"http\",\"\")\n",
        "    name = link.replace(\".html\",\"\")\n",
        "\n",
        "    name = name.replace(\"/lyrics/\",\"\")\n",
        "\n",
        "    # Replace useless chareacters with UNDERSCORE\n",
        "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\")\n",
        "\n",
        "    # tack on .txt\n",
        "    name = name + \".txt\"\n",
        "\n",
        "    return(name)"
      ],
      "metadata": {
        "id": "VVEOoYjgKSIb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the lyrics folder here. If you'd like to practice your programming, add functionality\n",
        "# that checks to see if the folder exists. If it does, then use shutil.rmtree to remove it and create a new one.\n",
        "import shutil\n",
        "if os.path.isdir(\"lyrics\") :\n",
        "    shutil.rmtree(\"lyrics/\")\n",
        "\n",
        "os.mkdir(\"lyrics\")"
      ],
      "metadata": {
        "id": "cwg0FMWRKV2U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urljoin\n",
        "\n",
        "url_stub = \"https://www.azlyrics.com\"\n",
        "start = time.time()\n",
        "output_folder = \"lyrics\"\n",
        "\n",
        "total_pages = 0\n",
        "\n",
        "for artist, artist_page in artists.items():\n",
        "    artist_folder = os.path.join(output_folder, artist)\n",
        "\n",
        "    # 1. Build a subfolder for the artist\n",
        "    if not os.path.exists(artist_folder):\n",
        "        os.makedirs(artist_folder)\n",
        "\n",
        "    # 2. Iterate over the lyrics pages\n",
        "    for lyrics_page in lyrics_pages:\n",
        "        # 3. Request the lyrics page.\n",
        "        lyrics_url = urljoin(url_stub, lyrics_page[2:])  # Use urljoin for correct URL formatting\n",
        "        lyrics_request = requests.get(artist_page)\n",
        "        time.sleep(5 + 10 * random.random())\n",
        "\n",
        "        if lyrics_request.status_code == 200:\n",
        "            lyrics_soup = BeautifulSoup(lyrics_request.text, 'html.parser')\n",
        "\n",
        "            # 4. Extract the title and lyrics from the page.\n",
        "            title = lyrics_soup.find('b', class_=None).text.strip()\n",
        "\n",
        "            # Find all div elements containing the lyrics\n",
        "            lyrics_elements = lyrics_soup.find_all('div', class_=None, recursive=False)\n",
        "\n",
        "            # Check if there are any elements in the list\n",
        "if lyrics_elements:\n",
        "    # Extract text from each tag inside the lyrics elements\n",
        "      lyrics = '\\n'.join([tag.get_text(separator='\\n').strip() for lyrics_element in lyrics_elements for tag in lyrics_element.find_all(['br', 'p'])])\n",
        "\n",
        "            # 5. Write out the title, two returns ('\\n'), and the lyrics.\n",
        "      filename = generate_filename_from_link(lyrics_page)\n",
        "      filepath = os.path.join(artist_folder, filename)\n",
        "      with open(filepath, 'w', encoding='utf-8') as file:\n",
        "          file.write(title + '\\n\\n' + lyrics)\n",
        "else:\n",
        "    print(f\"No lyrics elements found for {lyrics_page}\")\n",
        "            # Add a break statement if you only want to pull a certain number of songs per artist\n",
        "            # if total_pages >= 20:\n",
        "            #     break\n",
        "\n",
        "\n",
        "\n",
        "    # Use this space to carry out the following steps:\n",
        "\n",
        "    # 1. Build a subfolder for the artist\n",
        "    # 2. Iterate over the lyrics pages\n",
        "    # 3. Request the lyrics page.\n",
        "        # Don't forget to add a line like `time.sleep(5 + 10*random.random())`\n",
        "        # to sleep after making the request\n",
        "    # 4. Extract the title and lyrics from the page.\n",
        "    # 5. Write out the title, two returns ('\\n'), and the lyrics. Use `generate_filename_from_url`\n",
        "    #    to generate the filename.\n",
        "\n",
        "    # Remember to pull at least 20 songs per artist. It may be fun to pull all the songs for the artist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T52vIKKTKZQw",
        "outputId": "3ffb406c-e212-4844-c295-dcd943fcbdfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No lyrics elements found for ed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total run time was {round((time.time() - start)/3600,2)} hours.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3An_xYlKbXS",
        "outputId": "7e9bebb0-65f6-4513-9e6d-231fb57aecb7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total run time was 0.01 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Evaluation"
      ],
      "metadata": {
        "id": "1EMGDbbTJgTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple word extractor from Peter Norvig: https://norvig.com/spell-correct.html\n",
        "def words(text):\n",
        "    return re.findall(r'\\w+', text.lower())"
      ],
      "metadata": {
        "id": "N_6TMGasKfme"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Lyrics"
      ],
      "metadata": {
        "id": "kog5Bg4xKhOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artist_folders = os.listdir(\"lyrics/\")\n",
        "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
        "\n",
        "for artist in artist_folders :\n",
        "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
        "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
        "\n",
        "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
        "\n",
        "    artist_words = []\n",
        "\n",
        "    for f_name in artist_files :\n",
        "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile :\n",
        "            artist_words.extend(words(infile.read()))\n",
        "\n",
        "\n",
        "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")"
      ],
      "metadata": {
        "id": "8PQGsJ6dKh4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39668a63-c360-41d9-db55-4db4d1429034"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For ed we have 0 files.\n",
            "For ed we have roughly 0 words, 0 are unique.\n",
            "For taylor we have 0 files.\n",
            "For taylor we have roughly 0 words, 0 are unique.\n"
          ]
        }
      ]
    }
  ]
}