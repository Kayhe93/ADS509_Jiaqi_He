{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"/users/kayan/Desktop/USD/ADS_509/2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text,party\n",
    "                            FROM conventions;\n",
    "                            ''')\n",
    "\n",
    "for row in query_results:\n",
    "    text, party = row\n",
    "    convention_data.append([text, party])\n",
    "\n",
    "# Close the database connection\n",
    "convention_db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Congratulations, you’re now citizens of the United States of America. On behalf of the Department of Homeland Security, it is my honor to call you my fellow Americans. Mr. President, I want to again commend you for your dedication to the rule of law and for restoring integrity to our immigration system. Thank you for hosting such a patriotic celebration here at the White House today.',\n",
       "  'Republican'],\n",
       " ['I’m pleased to announce that Vice President Joe Biden has officially been nominated by the Democratic Party as our candidate for President of the United States.',\n",
       "  'Democratic'],\n",
       " ['Every generation before us has had to fight for what they believe in and it’s just our turn now. Jack G.: ( 01:02:03 )  I was proud when I saw the demonstrations that were going on across the country.',\n",
       "  'Democratic'],\n",
       " ['Joe Biden has selected Kamala Harris as his running mate.', 'Democratic'],\n",
       " ['American history tells us that’s been in our darkest moments that we’ve made our greatest progress that we found the light. In this dark moment I believe we’re poised to make great progress again, and we can find the light once more.',\n",
       "  'Democratic'],\n",
       " ['And when I’m reelected, the best is yet to come. Thank you very much. When I took office, the Middle East was in total chaos. ISIS was rampaging, Iran was on the rise, and the war in Afghanistan had no end in sight.',\n",
       "  'Republican'],\n",
       " ['I’m Rebecca Friedrichs, a veteran California public school educator. I’m here to give voice to America’s great teachers because our voices have been silenced for decades by unions who claim to represent us. They do not. When other dedicated teachers and I served within the unions, we spoke up in defense of children, parents, scientific fact and American values. For our trouble, we were brutalized, booed off the platform, barred from committees, shouted down and even spit upon by union leaders. This is how unions treat devoted teachers, but what’s even worse is how their agenda of control deceives Americans and our children. They’ve intentionally rewritten American history to perpetuate division, pervert the memories of our American founders and disparage our Judeo-Christian virtues. They’re lenient discipline policies morphed our schools into war zones and they back defunding police and abolishing ICE. Unions collect billions annually from unsuspecting teachers and push this radical agenda into our classrooms against our will. Why.',\n",
       "  'Republican'],\n",
       " ['She gave 100% from her energy to the students. She’s a great teacher.',\n",
       "  'Democratic'],\n",
       " ['Team USA will indeed take home the gold.', 'Republican'],\n",
       " ['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 19, 2020 Democratic National Convention (DNC) 2020 Night 3 Transcript: Speeches by Barack Obama, Kamala Harris, Hillary Clinton, Nancy Pelosi & more Rev  ›  Blog  › Transcripts  ›  2020 Election Transcripts  ›  Democratic National Convention (DNC) 2020 Night 3 Transcript: Speeches by Barack Obama, Kamala Harris, Hillary Clinton, Nancy Pelosi & more Night 3 of the 2020 Democratic National Convention (DNC) on August 19. Speakers include: Sen. and Vice-Presidential Nominee Kamala Harris, former Sec. of State and Democratic Nominee Hillary Clinton, House Speaker Nancy Pelosi, Sen. Elizabeth Warren, and former President Barack Obama. Read the full transcript of the event here. Transcribe Your Own Content Try Rev for free  and save time transcribing, captioning, and subtitling.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2891 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,feature_words) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * feature_words: the *feature words* that we're considering. A word \n",
    "            in `text` must be in feature_words in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `feature_words`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `feature_words` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    ret_dict = {word.strip().lower(): True for word in text.strip().lower().split() if word.strip().lower() in feature_words}\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': True, 'the': True, 'president': True}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features(\"donald is the president\",feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(feature_words)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(conv_features(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdonald is the president\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_words)\u001b[38;5;241m==\u001b[39m\n\u001b[1;32m      3\u001b[0m                      {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdonald\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpresident\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(conv_features(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msome people in america are citizens\u001b[39m\u001b[38;5;124m\"\u001b[39m,feature_words)\u001b[38;5;241m==\u001b[39m\n\u001b[1;32m      5\u001b[0m                      {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeople\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamerica\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitizens\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\", feature_words)==\n",
    "                     {'donald':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,'citizens':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.432\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
      "                supports = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
      "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
      "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
      "                freedom, = True           Republ : Democr =     13.4 : 1.0\n",
      "                 private = True           Republ : Democr =     11.9 : 1.0\n",
      "                freedom. = True           Republ : Democr =     11.5 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "                 special = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
      "                  dream, = True           Republ : Democr =     10.9 : 1.0\n",
      "              education, = True           Republ : Democr =     10.9 : 1.0\n",
      "                   trade = True           Republ : Democr =     10.5 : 1.0\n",
      "                   armed = True           Republ : Democr =      9.9 : 1.0\n",
      "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
      "              greatness. = True           Republ : Democr =      9.9 : 1.0\n",
      "                 liberal = True           Republ : Democr =      9.9 : 1.0\n",
      "                veterans = True           Republ : Democr =      9.9 : 1.0\n",
      "               wonderful = True           Republ : Democr =      9.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "The accuracy of nltk is 0.432, which means less than half of the instaces are classified correctly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"/users/kayan/Desktop/USD/ADS_509/congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "for row in results:\n",
    "    candidate, party, tweet_text = row\n",
    "    features = conv_features(tweet_text, feature_words)\n",
    "    tweet_data.append([features, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Republican and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Republican and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: {}\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = 'Gotta fill this in'\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = \"Gotta fill this in\"\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 0,\n",
       "                          'Democratic': 0,\n",
       "                          'Gotta fill this in': 4278}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 0,\n",
       "                          'Democratic': 0,\n",
       "                          'Gotta fill this in': 5724})})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The republican has 278 results and democratic has 5724 results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
